{
  "name": "@llamaindex/azure-inference",
  "description": "Azure AI Adapter for LlamaIndex",
  "version": "0.0.1",
  "type": "module",
  "main": "./dist/index.cjs",
  "module": "./dist/index.js",
  "exports": {
    ".": {
      "require": {
        "types": "./dist/index.d.cts",
        "default": "./dist/index.cjs"
      },
      "import": {
        "types": "./dist/index.d.ts",
        "default": "./dist/index.js"
      }
    }
  },
  "files": [
    "dist"
  ],
  "repository": {
    "type": "git",
    "url": "git+https://github.com/run-llama/LlamaIndexTS.git",
    "directory": "packages/providers/azure-inference"
  },
  "scripts": {
    "build": "bunchee",
    "dev": "bunchee --watch"
  },
  "devDependencies": {
    "bunchee": "6.4.0"
  },
  "dependencies": {
    "@azure-rest/ai-inference": "1.0.0-beta.5",
    "@azure/core-auth": "^1.9.0",
    "@azure/core-sse": "^2.1.3",
    "@llamaindex/core": "workspace:*",
    "@llamaindex/env": "workspace:*",
    "openai": "^4.86.0"
  }
}
